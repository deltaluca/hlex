package;

import scx.Set;
import scx.UStr;
import scx.FA;
import scx.LList;

import util.CharSet;
import util.RegExp;

import neko.Sys;
import neko.Lib;
import neko.io.File;

import HLex;
import HLlr;
import scx.Textual;

typedef Rule = { name:String, id:Int, attr:String, nfa:NFA(CharSet), ign:Bool };

class Main {
	static function main() {
		var args = Sys.args();
		
		if(args.length < 3 && args[0]!="--help") {
		    Lib.println("For help use option --help");
			Sys.exit(1);
			return;
		}
		
		if(args[0]=="--help") {

			Lib.println("Usage: hlex descriptor.hxl [options]");
			Lib.println("Options:");
			Lib.println("\t-haxe output.hx [-package package_name] -token TokenType");
			Lib.println("\t-c++ output -token TokenType -tokenincl includetoken");
			Lib.println("\t\tgenerating output.hpp and output.cpp requiring caxe_util.hpp from caXe project, -tokenincl to specify what file to include for the token type in the header (as plain code blocks become part of the parser cpp)");
			
		    Sys.exit(0);
		    return;
		}
		
		//------------------------------------------------------------------------------------------

		var epath = neko.Sys.getEnv("HLEX_ROOT");
		if(epath==null || epath.length==0) {
		    Lib.println("WARNING: HLEX_ROOT NOT DEFINED");
		    epath = "";
		};
	
		var packname = null;
		var haxemode:Null<Bool> = null;
		var tocktype = null;
		var outf = null;
		var tockincl = null;

		var iarg = 1;
		while(iarg < args.length) {
			var flag = args[iarg++];
			if(flag=="-haxe") {
				if(haxemode!=null) { Lib.println("Backend already set as "+(haxemode?"haxe":"c++")); Sys.exit(1); }
				haxemode = true;
				if(iarg == args.length) { Lib.println("Expected output file after -haxe"); Sys.exit(1); }
				outf = args[iarg++];
			}else if(flag=="-c++") {
				if(haxemode!=null) { Lib.println("Backend already set as "+(haxemode?"haxe":"c++")); Sys.exit(1); }
				haxemode = false;
				if(iarg == args.length) { Lib.println("Expected output name after -c++"); Sys.exit(1); }
				outf = args[iarg++];
			}else if(flag=="-package") {
				if(iarg == args.length) { Lib.println("Expected package name after -package"); Sys.exit(1); }
				packname = args[iarg++];
			}else if(flag=="-token") {
				if(iarg == args.length) { Lib.println("Expected typename after -token"); Sys.exit(1); }
				tocktype = args[iarg++];
			}else if(flag=="-tokenincl") {
				if(iarg == args.length) { Lib.println("Expected path after -tokenincl"); Sys.exit(1); }
				tockincl = args[iarg++];
			}else {
				Lib.println("Unrecognised flag "+flag);
				Sys.exit(1);
			}
		}

		if(haxemode==null) { Lib.println("Expected either -haxe or -c++ to be specified in args"); Sys.exit(1); }
		if(tocktype==null) { Lib.println("-token flag is required"); Sys.exit(1); }
		if(!haxemode && packname!=null) { Lib.println("-package cannot be used with -c++"); Sys.exit(1); }
		if(haxemode && tockincl!=null) { Lib.println("-tokenincl cannot be used with -haxe"); Sys.exit(1); }

		//------------------------------------------------------------------------------------------
		
		Lib.println(" >> Processing descriptor");
		
		var hxl = File.getContent(args[0]);
		var tokens = HLex.lexify(hxl);
		var hlx = HLlr.parse(tokens);
		
		//------------------------------------------------------------------------------------------
		
		Lib.println(" >> Building NFA");
		
		var extra = "";
		var rules = new StringMap(Rule)();
		var nfrules = new Array<NFA(CharSet)>();
		var tokenid = 1;
		var error_attr = null;
		
		var unique:String = "UNIQUE_";
		var unocnt:Int = 0;
		for(S in hlx) {
			switch(S) {
				case hIgnore(p,reg):
					var n = "IGNORE_"+(unocnt++);
					var nfa = RegExp.nfa(Unicode.fromString(reg));
					var rule = { name : n, id : -1, nfa : nfa, attr : null, ign : true };

					FaUtil(CharSet).attribute(nfa, p, function(_) return rule);

					nfrules.push(nfa);
					rules.insert(n, rule);

				case hDecl(p,reg,attr):
					var n = unique + (unocnt++);
					var nfa = RegExp.nfa(Unicode.fromString(reg));
					var rule = { name : n, id : tokenid++, nfa : nfa, attr : attr, ign : false };
					FaUtil(CharSet).attribute(nfa, p, function (_) return rule);

					nfrules.push(nfa);
					rules.insert(n,rule);

				case hExtra(haxe):
					extra += haxe;

				case hError(haxe):
					error_attr = haxe;	
			}
		}
		
		//------------------------------------------------------------------------------------------
		
		neko.Lib.println(" >> Building DFA");
		
		var nfa = FaUtil(CharSet).dfa_cons(nfrules);
		var dfa = FaUtil(CharSet).dfa(nfa);
		
		neko.Lib.println(" >> Minimalising DFA");

		dfa = FaUtil(CharSet).minimal(dfa);

		//------------------------------------------------------------------------------------------
		//output to file.
		
		neko.Lib.println(" >> Outputting to file");
		var out = "";
		
		if(!haxemode) {
			var out = "";
			out += "#pragma once\n";
			out += "\n";
			out += "#include <string>\n";
			out += "#include <iostream>\n";
			out += "#include <caxe_util.hpp>\n";
			out += "#include <"+tockincl+">\n";
/*			
			out += "struct TOKEN {\n";
			out += "	char id;\n";
			out += "	Dynamic data;\n";
			out += "	TOKEN();\n";
			out += "	TOKEN(char);\n";
			out += "	TOKEN(char, const Dynamic&);\n";
			out += "};\n";
			out += "std::ostream& operator<<(std::ostream&,const TOKEN&);\n";
*/			
			out += "class Lexer : public Thread {\n";
			out += "	ref<tsDeque<ptr<"+tocktype+"> > > tokens;\n";
			out += "	ref<tsDeque<std::string> > files;\n";
			
			out += "	size_t run();\n";
			out += "	void lexfile(const std::string&, char**, int&);\n";
			out += "public:\n";
			out += "	Lexer();\n";
			out += "	void init(tsDeque<std::string>&, tsDeque<ptr<"+tocktype+"> >&);\n";
			out += "};\n";
			
			var file = File.write(outf+".hpp", false);
			file.writeString(out);
			file.flush();
			file.close();
			
			var out = "";
			out += "#include <"+outf+".hpp>\n";
			out += "#include <cstdio>\n";
			out += "#include <string>\n";
			out += "#include <cstring>\n";
			out += "#include <cstdlib>\n";
			out += "#include <iostream>\n";
			out += "#include <caxe_util.hpp>\n";
			out += "#include <"+tockincl+">\n";
			
			out += extra+"\n";
			
/*			out += "TOKEN::TOKEN() {}\n";
			out += "TOKEN::TOKEN(char id) { this->id = id; }\n";
			out += "TOKEN::TOKEN(char id, const Dynamic& data) { this->id = id; this->data = data; }\n";
			
			out += "std::ostream& operator<<(std::ostream& out, const TOKEN& x) {\n";
			out += "	return out << \"{\" << (int)x.id << \", \" << x.data << \"}\";\n";
			out += "}\n";*/
			
			out += "Lexer::Lexer() {}\n";
			out += "void Lexer::init(tsDeque<std::string>& files, tsDeque<ptr<"+tocktype+"> >& tokens) {\n";
			out += "	this->files = files;\n";
			out += "	this->tokens = tokens;\n";
			out += "}\n";
			
			out += "struct Transition {\n";
			out += "	short state;\n";
			out += "	char flags;\n";
			out += "	union { ptr<"+tocktype+"> (*token)(const std::string&); char id; };\n";
			
			out += "	Transition() { state = -1; flags = 0; token = NULL; }\n";
			out += "	Transition(short a, char b, ptr<"+tocktype+">(*c)(const std::string&)) { state = a; flags = b; token = c; }\n";
			out += "	Transition(short a, char b) { state = a; flags = b; token = NULL; }\n";
			out += "	Transition(short a, char b, char c) { state = a; flags = b; id = c; }\n";
			out += "};\n";
			
			$(mixin arrstr(x,f,LEFT,RIGHT) {
				var ret = LEFT;
				var fst = true;
				for(i in x) {
					if(!fst) ret += ",";
					fst = false;
					ret += f(i);
				}
				ret += RIGHT;
				ret;
			});

			var states = FaUtil(CharSet).split_states(dfa).all;
			var cnt = 0;
			for(state in states) cnt++;
			
			var map = new StringSet();
			for(state in states) {
				if(!state.accepting) continue;
				var rule = state.attr.func("");
				if(rule.ign) continue;
				
				if(!map.insert(rule.name)) continue;
				if(rule.attr==null) continue;
				
			out += "ptr<"+tocktype+"> token_"+rule.name+"(const std::string& valstr) {\n";
			out += "	"+tocktype+"* retval;\n	";
				var esc = false;
				for(i in 0...rule.attr.length) {
					var c = rule.attr.charCodeAt(i);
					if(c==Unicode.wchar('\\') && !esc) {
						esc = true; out += '\\';
					}else if(esc) {
						esc = false; out += rule.attr.charAt(i);
					}else if(c == Unicode.wchar('%')) {
						out += " valstr ";
					}else out += rule.attr.charAt(i);
				}
			out += "	return ptr<"+tocktype+">(retval);\n";
//			out += "	return ptr<TOKEN>(new TOKEN("+(rule.id-1)+",retval));\n";
			out += "}\n";
			}
			
			out += "void err_token(ref<tsDeque<ptr<"+tocktype+"> > >& tokens, std::string& errstr) {\n";
			out += "	if(errstr.length()!=0) {\n";
			if(error_attr==null) out += "		tokens->push(ptr<"+tocktype+">::null)\n";
			else {
			out += "		"+tocktype+"* retval;\n	";
				var esc = false;
				for(i in 0...error_attr.length) {
					var c = error_attr.charCodeAt(i);
					if(c==Unicode.wchar('\\') && !esc) {
						esc = true; out += '\\';
					}else if(esc) {
						esc = false; out += error_attr.charAt(i);
					}else if(c == Unicode.wchar('%')) {
						out += " errstr ";
					}else out += error_attr.charAt(i);
				}
			out += "		tokens->push(ptr<"+tocktype+">(retval));\n";
			}
//			if(error_node==null)
//			out += "		tokens->push(ptr<TOKEN>(new TOKEN(-1,Dynamic(errstr))));\n";
//			else
//			out += "		tokens->push(ptr<TOKEN>(new TOKEN("+(error_node.id-1)+",Dynamic(errstr))));\n";
			out += "		errstr.clear();\n";
			out += "	}\n";
			out += "}\n";
			
			out += "#define ET Transition()\n";
			out += "#define T2(a,b) Transition(a,b)\n";
			out += "#define T3(a,b,c) Transition(a,b,c)\n";
			out += "static const Transition transitions["+((RegExp.maxpoint+1)*cnt)+"] = \n";
			out += arrstr(states, function(state:FaNode(CharSet)) {
				var outs = [];
				for(i in 0...RegExp.maxpoint+1) outs.push(null);
				for(out in state.out) {
					var dat = if(out.to.accepting) {
						var rule = out.to.attr.func("");
						var flags = 1;
						var data:String = null;
						if(rule.ign) {}
						else {
							flags |= 2;
							if(rule.attr!=null) {
								flags |= 4;
								data = "&token_"+rule.name;
							}else {
								var rid = rule.id-1;
								data = Std.string(rid);
							}
						}
						{ state : out.to.id, flags : flags, data : data };
					}else
						{ state : out.to.id, flags : 0, data : null };
					
					var x:CharSet = out.match;
					LLIter(R,x.ranges,{
						for(i in R.from...R.to+1) {
							if(out.to.id==-1) outs[i] = null;
							else outs[i] = dat;
						}
					});
				}
				
				return "\n "+arrstr(outs, function(i:{state:Int,flags:Int,data:String}) {
					if(i==null) return "ET";
					else {
						if(i.data==null) return "T2("+Std.string(i.state)+","+Std.string(i.flags)+")";
						else
							return "T3("+Std.string(i.state)+","+Std.string(i.flags)+","+i.data+")";
					}
				},
				"","");
			},
			"{","}");
			out += ";\n";
			out += "#undef ET\n";
			out += "#undef T2\n";
			out += "#undef T3\n";
			
			out += "static const short entry_state = "+dfa.id+";\n";
			out += "static const int maxpoint = "+RegExp.maxpoint+";\n";

			var lex = File.getContent(epath+"/scripts/hlex_lexer_c++");
			lex = (~/TOKEN/).replace(lex,tocktype);
//			out += File.getContent(epath+"/scripts/hlex_lexer_c++");
			out += lex;

			var file = File.write(outf+".cpp", false);
			file.writeString(out);
			file.flush();
			file.close();
		}else {
			out += "package "+(packname==null?"":packname)+";\n";
			out += extra;
			out += "class HLex {\n";
			out += "	static inline var entry_state:Int = "+dfa.id+";\n";
			out += "	static var transitions:Array<Array<Array<Int>>> = null;\n";
			out += "	public static function init() {\n";
			out += "		if(transitions!=null) return;\n";
			out += "		transitions = [];\n";
			var states = FaUtil(CharSet).split_states(dfa).all;
			for(state in states) {
				if(state.out.length==0) { out += "transitions.push(null);\n"; continue; }
				out += "var cur = [];\n";
				for(ssout in state.out) {
					var x:CharSet = ssout.match;
					LLIter(R, x.ranges, {
						out += "cur.push(["+(R.from)+","+(R.to)+","+(ssout.to.id)+"]);\n";	
					});
				}
				out += "transitions.push(cur);\n";
			}
			out += "}\n";

			//--------------------------------------------------------------------------------------
			
			out += "        static var accepting = ";
			out += Textual.array_string(cast states, function(state:FaNode(CharSet)) {
				return if(state.accepting) "true" else "false";
			});
			out += ";\n";
			
			//--------------------------------------------------------------------------------------
			
			out += "	public static function lexify(input:String):Array<"+tocktype+"> {\n";
			out += "		init();\n";	
			//--------------------------------------------------------------------------------------
			
			
			out += "var ret = new Array<"+tocktype+">();\n";
			out += File.getContent(epath+"/scripts/hlex_lexer");

			out += "}\n";

			out += "	static inline function errtok(hxl_match:String):"+tocktype+" {\n";
			if(error_attr==null) out += "		return null;\n";
			else {
				out += "return ({";
					var esc = false;
					for(i in 0...error_attr.length) {
						var c = error_attr.charCodeAt(i);
						if(c==Unicode.wchar('\\') && !esc) {
							esc = true; out += '\\';
						}else if(esc) {
							esc = false; out += error_attr.charAt(i);
						}else if(c == Unicode.wchar('%')) {
							out += " hxl_match ";
						}else out += error_attr.charAt(i);
					}
				out += "});\n";
			}
			out += "	}\n";

			out += "	static function tokenof(id:Int, hxl_match:String):"+tocktype+" {\n";
			out += "		switch(id) {\n";
			out += "			default: return null;\n";
			for(x in states) {
				if(!x.accepting || x.attr==null) continue;
				var rule = x.attr.func("");
				if(rule.ign) continue;
				out += "            case "+x.id+":\n";
				out += "				return ";
				if(rule.attr != null) {
					out += "({";
					var esc = false;
					for(i in 0...rule.attr.length) {
						var c = rule.attr.charCodeAt(i);
						if(c==Unicode.wchar('\\') && !esc) {
							esc = true; out += '\\';
						}else if(esc) {
							esc = false; out += rule.attr.charAt(i);
						}else if(c == Unicode.wchar('%')) {
							out += " hxl_match ";
						}else out += rule.attr.charAt(i);
					}
					out += "})";
				}else out += "null";
				out += ";\n";
			}
			out += "        }\n";
			out += "	}\n";
			out += "}\n";

			var file = File.write(outf, false);
			file.writeString(out);
			file.flush();
			file.close();
		}

		Sys.exit(0);
		return;
	}
}


class CharRangeInt {
	public var from:WChar;
	public var to  :WChar;
	public var target:Int;
	
	public function new(from:WChar, to:WChar, target:Int) {
		this.from = from;
		this.to = to;
		this.target = target;
	}
	
	public inline function compare(x:CharRangeInt) {
		if     (from < x.from) return -1;
		else if(from > x.from) return 1;
		else if(to < x.to) return -1;
		else if(to > x.to) return 1;
		else return 0;
	}
}
